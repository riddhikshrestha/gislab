{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest algorithmn with GEE - Accuracy Assesment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the accuracy of a classifier, use a `ConfusionMatrix`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an interactive map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5281ba3fd70b4aa98e8a265d0d6aca93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = geemap.Map()\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add data to the map\n",
    "\n",
    "Let's add the [USGS National Land Cover Database](https://developers.google.com/earth-engine/datasets/catalog/USGS_NLCD), which can be used to create training data with class labels. \n",
    "\n",
    "![](https://i.imgur.com/7QoRXxu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLCD2016 = ee.Image('USGS/NLCD/NLCD2016').select('landcover')\n",
    "Map.addLayer(NLCD2016, {}, 'NLCD 2016')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the NLCD metadata to find out the Landsat image IDs used to generate the land cover data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLCD_metadata = ee.FeatureCollection(\"users/giswqs/landcover/NLCD2016_metadata\")\n",
    "Map.addLayer(NLCD_metadata, {}, 'NLCD Metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = ee.Geometry.Point([-88.3070, 41.7471])  # Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = NLCD_metadata.filterBounds(point).first()\n",
    "region = metadata.geometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LC08_2016256'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.get('2016on_bas').getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016256'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doy = metadata.get('2016on_bas').getInfo().replace('LC08_', '')\n",
    "doy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016-09-12'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee.Date.parse('YYYYDDD', doy).format('YYYY-MM-dd').getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = ee.Date.parse('YYYYDDD', doy)\n",
    "end_date = start_date.advance(1, 'day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5281ba3fd70b4aa98e8a265d0d6aca93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[41.74710000000001, -88.307], controls=(WidgetControl(options=['position', 'transparent_bg'], widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = (\n",
    "    ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\n",
    "    .filterBounds(point)\n",
    "    .filterDate(start_date, end_date)\n",
    "    .first()\n",
    "    .select('B[1-7]')\n",
    "    .clip(region)\n",
    ")\n",
    "\n",
    "vis_params = {'min': 0, 'max': 3000, 'bands': ['B5', 'B4', 'B3']}\n",
    "\n",
    "Map.centerObject(point, 8)\n",
    "Map.addLayer(image, vis_params, \"Landsat-8\")\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlcd_raw = NLCD2016.clip(region)\n",
    "Map.addLayer(nlcd_raw, {}, 'NLCD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for consecutive class labels\n",
    "\n",
    "In this example, we are going to use the [USGS National Land Cover Database (NLCD)](https://developers.google.com/earth-engine/datasets/catalog/USGS_NLCD) to create label dataset for training.\n",
    "\n",
    "First, we need to use the `remap()` function to turn class labels into consecutive integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 12, 21, 22, 23, 24, 31, 41, 42, 43, 51, 52, 71, 72, 73, 74, 81, 82, 90, 95]\n"
     ]
    }
   ],
   "source": [
    "raw_class_values = nlcd_raw.get('landcover_class_values').getInfo()\n",
    "print(raw_class_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(raw_class_values)\n",
    "new_class_values = list(range(0, n_classes))\n",
    "new_class_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['476ba1', 'd1defa', 'decaca', 'd99482', 'ee0000', 'ab0000', 'b3aea3', '68ab63', '1c6330', 'b5ca8f', 'a68c30', 'ccba7d', 'e3e3c2', 'caca78', '99c247', '78ae94', 'dcd93d', 'ab7028', 'bad9eb', '70a3ba']\n"
     ]
    }
   ],
   "source": [
    "class_palette = nlcd_raw.get('landcover_class_palette').getInfo()\n",
    "print(class_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlcd = nlcd_raw.remap(raw_class_values, new_class_values).select(\n",
    "    ['remapped'], ['landcover']\n",
    ")\n",
    "nlcd = nlcd.set('landcover_class_values', new_class_values)\n",
    "nlcd = nlcd.set('landcover_class_palette', class_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5281ba3fd70b4aa98e8a265d0d6aca93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[41.74710000000001, -88.307], controls=(WidgetControl(options=['position', 'transparent_bg'], widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map.addLayer(nlcd, {}, 'NLCD')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the training dataset.\n",
    "points = nlcd.sample(\n",
    "    **{\n",
    "        'region': region,\n",
    "        'scale': 30,\n",
    "        'numPixels': 5000,\n",
    "        'seed': 0,\n",
    "        'geometries': True,  # Set this to False to ignore geometries\n",
    "    }\n",
    ")\n",
    "\n",
    "Map.addLayer(points, {}, 'training', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(points.size().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Feature', 'geometry': {'type': 'Point', 'coordinates': [-88.56212124700772, 42.210469414463425]}, 'id': '0', 'properties': {'landcover': 17}}\n"
     ]
    }
   ],
   "source": [
    "print(points.first().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these bands for prediction.\n",
    "bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
    "\n",
    "# This property of the table stores the land cover labels.\n",
    "label = 'landcover'\n",
    "\n",
    "# Overlay the points on the imagery to get training.\n",
    "sample = image.select(bands).sampleRegions(\n",
    "    **{'collection': points, 'properties': [label], 'scale': 30}\n",
    ")\n",
    "\n",
    "# Adds a column of deterministic pseudorandom numbers.\n",
    "sample = sample.randomColumn()\n",
    "\n",
    "split = 0.7\n",
    "\n",
    "training = sample.filter(ee.Filter.lt('random', split))\n",
    "validation = sample.filter(ee.Filter.gte('random', split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Feature',\n",
       " 'geometry': None,\n",
       " 'id': '2_0',\n",
       " 'properties': {'B1': 72,\n",
       "  'B2': 215,\n",
       "  'B3': 579,\n",
       "  'B4': 543,\n",
       "  'B5': 2558,\n",
       "  'B6': 1782,\n",
       "  'B7': 1103,\n",
       "  'landcover': 3,\n",
       "  'random': 0.18158720869622524}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.first().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Feature',\n",
       " 'geometry': None,\n",
       " 'id': '0_0',\n",
       " 'properties': {'B1': 174,\n",
       "  'B2': 223,\n",
       "  'B3': 614,\n",
       "  'B4': 368,\n",
       "  'B5': 4221,\n",
       "  'B6': 1737,\n",
       "  'B7': 766,\n",
       "  'landcover': 17,\n",
       "  'random': 0.889822614157854}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.first().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier\n",
    "\n",
    "In this examples, we will use random forest classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ee.Classifier.smileRandomForest(10).train(training, label, bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5281ba3fd70b4aa98e8a265d0d6aca93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[41.74710000000001, -88.307], controls=(WidgetControl(options=['position', 'transparent_bg'], widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classify the image with the same bands used for training.\n",
    "result = image.select(bands).classify(classifier)\n",
    "\n",
    "# # Display the clusters with random colors.\n",
    "Map.addLayer(result.randomVisualizer(), {}, 'classfied')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render categorical map\n",
    "\n",
    "To render a categorical map, we can set two image properties: `classification_class_values` and `classification_class_palette`. We can use the same style as the NLCD so that it is easy to compare the two maps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "class_values = nlcd.get('landcover_class_values').getInfo()\n",
    "print(class_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['476ba1', 'd1defa', 'decaca', 'd99482', 'ee0000', 'ab0000', 'b3aea3', '68ab63', '1c6330', 'b5ca8f', 'a68c30', 'ccba7d', 'e3e3c2', 'caca78', '99c247', '78ae94', 'dcd93d', 'ab7028', 'bad9eb', '70a3ba']\n"
     ]
    }
   ],
   "source": [
    "class_palette = nlcd.get('landcover_class_palette').getInfo()\n",
    "print(class_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover = result.set('classification_class_values', class_values)\n",
    "landcover = landcover.set('classification_class_palette', class_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5281ba3fd70b4aa98e8a265d0d6aca93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[41.74710000000001, -88.307], controls=(WidgetControl(options=['position', 'transparent_bg'], widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map.addLayer(landcover, {}, 'Land cover')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a legend to the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5281ba3fd70b4aa98e8a265d0d6aca93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[41.74710000000001, -88.307], controls=(WidgetControl(options=['position', 'transparent_bg'], widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map.add_legend(builtin_legend='NLCD')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training dataset\n",
    "\n",
    "`confusionMatrix()` computes a 2D confusion matrix for a classifier based on its training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = classifier.confusionMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[272, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2, 0, 183, 6, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 0, 0],\n",
       " [0, 0, 1, 421, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 0, 0],\n",
       " [1, 0, 1, 15, 171, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 3, 8, 96, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n",
       " [0, 0, 2, 2, 0, 0, 0, 212, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 2, 0, 13, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 32, 0, 0, 0, 0, 4, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 88, 14, 0, 0],\n",
       " [1, 0, 1, 4, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1730, 0, 0],\n",
       " [0, 0, 1, 1, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 56, 0],\n",
       " [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 10]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy.getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall Accuracy essentially tells us out of all of the reference sites what proportion were mapped correctly. The overall accuracy is usually expressed as a percent, with 100% accuracy being a perfect classification where all reference site were classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9562445667922341"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy.accuracy().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Kappa Coefficient` is generated from a statistical test to evaluate the accuracy of a classification. Kappa essentially evaluates how well the classification performed as compared to just randomly assigning values, i.e. did the classification do better than random. The Kappa Coefficient can range from -1 t0 1. A value of 0 indicated that the classification is no better than a random classification. A negative number indicates the classification is significantly worse than random. A value close to 1 indicates that the classification is significantly better than random. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9376575979043613"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy.kappa().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated = validation.classify(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Feature',\n",
       " 'geometry': None,\n",
       " 'id': '0_0',\n",
       " 'properties': {'B1': 174,\n",
       "  'B2': 223,\n",
       "  'B3': 614,\n",
       "  'B4': 368,\n",
       "  'B5': 4221,\n",
       "  'B6': 1737,\n",
       "  'B7': 766,\n",
       "  'classification': 17,\n",
       "  'landcover': 17,\n",
       "  'random': 0.889822614157854}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validated.first().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`errorMatrix` computes a 2D error matrix for a collection by comparing two columns of a collection: one containing the actual values, and one containing predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = validated.errorMatrix('landcover', 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[145, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2, 0, 13, 18, 2, 0, 0, 15, 0, 0, 0, 0, 1, 0, 0, 0, 2, 54, 1, 0],\n",
       " [2, 0, 8, 113, 20, 2, 1, 7, 0, 0, 0, 0, 1, 0, 0, 0, 3, 33, 3, 0],\n",
       " [1, 0, 1, 27, 34, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 0],\n",
       " [0, 0, 1, 2, 18, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n",
       " [0, 0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 12, 6, 1, 0, 0, 54, 0, 0, 0, 0, 0, 0, 0, 0, 1, 14, 5, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 10, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 7, 10, 2, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 2, 25, 0, 0],\n",
       " [0, 0, 11, 37, 2, 4, 0, 10, 0, 0, 0, 0, 1, 0, 0, 0, 4, 708, 0, 0],\n",
       " [0, 0, 4, 7, 0, 0, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0],\n",
       " [0, 0, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 0]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7023886378308586"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.accuracy().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5639057934062713"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.kappa().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download confusion matrix\n",
    "We download generated confusion matrix result into respective csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "out_dir = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "training_csv = os.path.join(out_dir, 'train_accuracy.csv')\n",
    "testing_csv = os.path.join(out_dir, 'test_accuracy.csv')\n",
    "\n",
    "with open(training_csv, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(train_accuracy.getInfo())\n",
    "\n",
    "with open(testing_csv, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(test_accuracy.getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reclassify land cover map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover = landcover.remap(new_class_values, raw_class_values).select(\n",
    "    ['remapped'], ['classification']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover = landcover.set('classification_class_values', raw_class_values)\n",
    "landcover = landcover.set('classification_class_palette', class_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5281ba3fd70b4aa98e8a265d0d6aca93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[41.74710000000001, -88.307], controls=(WidgetControl(options=['position', 'transparent_bg'], widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map.addLayer(landcover, {}, 'Final land cover')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the result\n",
    "\n",
    "Export the result directly to our computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "out_dir = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "out_file = os.path.join(out_dir, 'landcover.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/d994d3a3f05a1501eb943e006b2a6b39-396ae47295b335d9a2be90326632e3ce:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /home/ridhhi/Downloads/landcover.tif\n"
     ]
    }
   ],
   "source": [
    "geemap.ee_export_image(landcover, filename=out_file, scale=900)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Table of Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
